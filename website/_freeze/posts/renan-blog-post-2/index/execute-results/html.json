{
  "hash": "d0f8e3a500e10e035e088a81e90e40b3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"House Dataset Exploration\"\ndescription: \"Exploring House price datasets for CAP-6771 (Fall 2025)\"\nauthor:\n  - name: Renan monteiro barbosa\n    url: https://github.com/renanmb\n    affiliation: Master of Data Science Program @ The University of West Florida (UWF)\n    # affiliation-url: https://ucsb-meds.github.io/\n# date: 10-24-2022\ncategories: [renan]\n# citation:\n#   url: https://samanthacsik.github.io/posts/2022-10-24-my-blog-post/\nimage: images/spongebob-imagination.jpg\ndraft: false\nbibliography: references.bib\nlink-citations: true\n---\n\nThis report has a very basic exploration of the dataset for sake of simplicity and to keep it a small report, further exploration will be continuosly update on the project page: https://github.com/renanmb/CAP-6771---Data-Mining-Project\n\n## 1. Introduction\n\nOn this blog post we will be exploring several data sources for the House Price Forecasting project and evaluating what can be done and what the next steps we must take to properly aanswer the research questions. \n\nRun the following command to download the [Zillow Economics Data](https://www.kaggle.com/datasets/zillow/zecon) @ZHVI:\n\n```{{bash}}\n#!/bin/bash\ncurl -L -o ~/Downloads/zecon.zip\\\n  https://www.kaggle.com/api/v1/datasets/download/zillow/zecon\n```\n\n### 1.1 Load packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"fpp3\")\nlibrary(fpp3)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(ggtime)\nlibrary(patchwork)\n```\n:::\n\n\n## 2. Load the Dataset\n\nThe following code will locate the folder **datasets** and then it will give back the variable **datasets_path** which you can use to build the path to the desired data to be loaded.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nfind_git_root <- function(start = getwd()) {\n  path <- normalizePath(start, winslash = \"/\", mustWork = TRUE)\n  while (path != dirname(path)) {\n    if (dir.exists(file.path(path, \".git\"))) return(path)\n    path <- dirname(path)\n  }\n  stop(\"No .git directory found — are you inside a Git repository?\")\n}\n\nrepo_root <- find_git_root()\ndatasets_path <- file.path(repo_root, \"datasets\")\nzillow_economics_data_path <- file.path(datasets_path, \"zillow-economics-data-01\")\n\nstate_time_series <- file.path(zillow_economics_data_path, \"State_time_series.csv\")\nall_states_data <- read.csv(state_time_series)\n```\n:::\n\n\n\n## 3. Exploring Data\n\nThe 'Date' column is a character, let's convert it to a Date object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Inspect the data structure\nstr(all_states_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t13212 obs. of  82 variables:\n $ Date                                                         : chr  \"1996-04-30\" \"1996-04-30\" \"1996-04-30\" \"1996-04-30\" ...\n $ RegionName                                                   : chr  \"Alabama\" \"Arizona\" \"Arkansas\" \"California\" ...\n $ DaysOnZillow_AllHomes                                        : num  NA NA NA NA NA NA NA NA NA NA ...\n $ InventorySeasonallyAdjusted_AllHomes                         : int  NA NA NA NA NA NA NA NA NA NA ...\n $ InventoryRaw_AllHomes                                        : int  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPricePerSqft_1Bedroom                           : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPricePerSqft_2Bedroom                           : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPricePerSqft_3Bedroom                           : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPricePerSqft_4Bedroom                           : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPricePerSqft_5BedroomOrMore                     : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPricePerSqft_AllHomes                           : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPricePerSqft_CondoCoop                          : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPricePerSqft_DuplexTriplex                      : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPricePerSqft_SingleFamilyResidence              : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPrice_1Bedroom                                  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPrice_2Bedroom                                  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPrice_3Bedroom                                  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPrice_4Bedroom                                  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPrice_5BedroomOrMore                            : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPrice_AllHomes                                  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPrice_CondoCoop                                 : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPrice_DuplexTriplex                             : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianListingPrice_SingleFamilyResidence                     : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianPctOfPriceReduction_AllHomes                           : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianPctOfPriceReduction_CondoCoop                          : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianPctOfPriceReduction_SingleFamilyResidence              : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianPriceCutDollar_AllHomes                                : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianPriceCutDollar_CondoCoop                               : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianPriceCutDollar_SingleFamilyResidence                   : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPricePerSqft_1Bedroom                            : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPricePerSqft_2Bedroom                            : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPricePerSqft_3Bedroom                            : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPricePerSqft_4Bedroom                            : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPricePerSqft_5BedroomOrMore                      : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPricePerSqft_AllHomes                            : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPricePerSqft_CondoCoop                           : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPricePerSqft_DuplexTriplex                       : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPricePerSqft_MultiFamilyResidence5PlusUnits      : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPricePerSqft_SingleFamilyResidence               : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPricePerSqft_Studio                              : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPrice_1Bedroom                                   : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPrice_2Bedroom                                   : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPrice_3Bedroom                                   : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPrice_4Bedroom                                   : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPrice_5BedroomOrMore                             : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPrice_AllHomes                                   : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPrice_CondoCoop                                  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPrice_DuplexTriplex                              : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPrice_MultiFamilyResidence5PlusUnits             : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPrice_SingleFamilyResidence                      : num  NA NA NA NA NA NA NA NA NA NA ...\n $ MedianRentalPrice_Studio                                     : num  NA NA NA NA NA NA NA NA NA NA ...\n $ ZHVIPerSqft_AllHomes                                         : int  50 62 42 102 82 85 71 56 55 185 ...\n $ PctOfHomesDecreasingInValues_AllHomes                        : num  NA NA NA NA NA NA NA NA NA NA ...\n $ PctOfHomesIncreasingInValues_AllHomes                        : num  NA NA NA NA NA NA NA NA NA NA ...\n $ PctOfHomesSellingForGain_AllHomes                            : num  NA NA NA NA NA NA NA NA NA NA ...\n $ PctOfHomesSellingForLoss_AllHomes                            : num  NA NA NA NA NA NA NA NA NA NA ...\n $ PctOfListingsWithPriceReductionsSeasAdj_AllHomes             : num  NA NA NA NA NA NA NA NA NA NA ...\n $ PctOfListingsWithPriceReductionsSeasAdj_CondoCoop            : num  NA NA NA NA NA NA NA NA NA NA ...\n $ PctOfListingsWithPriceReductionsSeasAdj_SingleFamilyResidence: num  NA NA NA NA NA NA NA NA NA NA ...\n $ PctOfListingsWithPriceReductions_AllHomes                    : num  NA NA NA NA NA NA NA NA NA NA ...\n $ PctOfListingsWithPriceReductions_CondoCoop                   : num  NA NA NA NA NA NA NA NA NA NA ...\n $ PctOfListingsWithPriceReductions_SingleFamilyResidence       : num  NA NA NA NA NA NA NA NA NA NA ...\n $ PriceToRentRatio_AllHomes                                    : num  NA NA NA NA NA NA NA NA NA NA ...\n $ Sale_Counts                                                  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ Sale_Counts_Seas_Adj                                         : num  NA NA NA NA NA NA NA NA NA NA ...\n $ Sale_Prices                                                  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ ZHVI_1bedroom                                                : int  61500 59200 53000 93700 77800 64700 90100 45400 74900 152300 ...\n $ ZHVI_2bedroom                                                : int  48900 86400 54500 123400 97500 97000 88200 65400 64700 186600 ...\n $ ZHVI_3bedroom                                                : int  78200 96100 76800 150900 129000 130400 103500 89100 88000 231800 ...\n $ ZHVI_4bedroom                                                : int  146500 128400 135100 196100 176100 194800 157800 133600 149700 303400 ...\n $ ZHVI_5BedroomOrMore                                          : int  206300 190500 186000 265300 212900 299800 176100 199900 212800 345500 ...\n $ ZHVI_AllHomes                                                : int  79500 103600 64400 157900 128100 132000 106800 86300 92000 227400 ...\n $ ZHVI_BottomTier                                              : int  45600 67100 38400 95100 82700 83700 77200 52500 57200 144500 ...\n $ ZHVI_CondoCoop                                               : int  99500 78900 70300 136100 99400 85000 NA 70600 89300 177000 ...\n $ ZHVI_MiddleTier                                              : int  79500 103600 64400 157900 128100 132000 106800 86300 92000 227400 ...\n $ ZHVI_SingleFamilyResidence                                   : int  79000 107500 64500 162000 133600 141000 107400 92100 92400 262600 ...\n $ ZHVI_TopTier                                                 : int  140200 168700 115200 270600 209300 231600 161600 155300 163900 374700 ...\n $ ZRI_AllHomes                                                 : int  NA NA NA NA NA NA NA NA NA NA ...\n $ ZRI_AllHomesPlusMultifamily                                  : int  NA NA NA NA NA NA NA NA NA NA ...\n $ ZriPerSqft_AllHomes                                          : num  NA NA NA NA NA NA NA NA NA NA ...\n $ Zri_MultiFamilyResidenceRental                               : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Zri_SingleFamilyResidenceRental                              : int  NA NA NA NA NA NA NA NA NA NA ...\n```\n\n\n:::\n:::\n\n\nNow we Convert 'Date' column to a Date object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_states_data$Date <- as.Date(all_states_data$Date)\n```\n:::\n\n\nLets Check how many N/As and think about\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Count total NAs per column\ncolSums(is.na(all_states_data))\n```\n:::\n\n\nMaking it pretty\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get the total number of rows for calculating percentages\ntotal_rows <- nrow(all_states_data)\n\n# Create a pretty summary table\nna_summary <- all_states_data %>%\n  # 1. Count NAs for every column\n  summarise(across(everything(), ~sum(is.na(.)))) %>%\n  \n  # 2. Pivot the data from wide to long\n  pivot_longer(everything(),\n               names_to = \"Column\",\n               values_to = \"NA_Count\") %>%\n  \n  # 3. (Optional) Filter to only show columns that HAVE NAs\n  filter(NA_Count > 0) %>%\n  \n  # 4. (Optional) Add a percentage column\n  mutate(NA_Percentage = (NA_Count / total_rows) * 100) %>%\n\n  # 5. Sort by the highest NA count\n  arrange(desc(NA_Count))\n\n# Print the clean table\nprint(na_summary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 80 × 3\n   Column                                  NA_Count NA_Percentage\n   <chr>                                      <int>         <dbl>\n 1 PctOfHomesSellingForGain_AllHomes          12609          95.4\n 2 PctOfHomesSellingForLoss_AllHomes          12609          95.4\n 3 MedianRentalPrice_5BedroomOrMore           11994          90.8\n 4 MedianRentalPricePerSqft_5BedroomOrMore    11752          88.9\n 5 MedianRentalPricePerSqft_Studio            10875          82.3\n 6 MedianRentalPrice_CondoCoop                10437          79.0\n 7 MedianRentalPricePerSqft_DuplexTriplex     10293          77.9\n 8 MedianRentalPrice_Studio                   10211          77.3\n 9 MedianListingPrice_1Bedroom                10205          77.2\n10 MedianRentalPrice_DuplexTriplex            10068          76.2\n# ℹ 70 more rows\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#  Some random tinkering\n# head(all_states_data)\n# summary(all_states_data)\n```\n:::\n\n\n\n## 4. Time Series Initial Analysis\n\nNow we will further explore the dataset. As we could observe that the dataset is large and has many columns for metrics we must continue to filter for a specific state and metric to start making this more manageable. Then later we will come back to explore the full dataset and the other datasets.\n\n### 4.1 Zillow Economics Data\n\nWe create the timeseries object using 'tsibble' which is a time-aware data frame. This is the standard object for the 'fpp3' workflow. Then we index the time component.\n\nFor sake of simplicity we are going to focus for now on a single State (California) and the Zillow Home Value Index (ZHVI_AllHomes) over time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Let's analyze the Zillow Home Value Index (ZHVI_AllHomes) for \"California\".\ncali_zhvi <- all_states_data %>%\n  filter(RegionName == \"California\") %>%\n  select(Date, ZHVI_AllHomes) %>%\n  # Remove any missing values for this metric\n  na.omit()\n```\n:::\n\n\nJust a quick check:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Inspect the new, focused data frame\nhead(cali_zhvi)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        Date ZHVI_AllHomes\n1 1996-04-30        157900\n2 1996-05-31        157800\n3 1996-06-30        157500\n4 1996-07-31        157300\n5 1996-08-31        157000\n6 1996-09-30        156800\n```\n\n\n:::\n:::\n\n\nMaking the Time Series object cali_ts:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncali_ts <- cali_zhvi %>%\n  as_tsibble(index = Date)\n```\n:::\n\n\nFurther experiments need to handle the N/As when filling the gaps:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# We set 'Date' as the 'index' (the time component).\ncali_ts_fill_gaps <- cali_zhvi %>%\n  as_tsibble(index = Date) %>%\n  fill_gaps()\n# If you were analyzing multiple states, you would add a 'key'.\n# Example for multiple states (not run here):\n# multi_state_ts <- all_states_data %>%\n#   select(Date, RegionName, ZHVI_AllHomes) %>%\n#   as_tsibble(index = Date, key = RegionName)\n```\n:::\n\n\nLets see how many N/As after filling the gaps:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Count total NAs per column\ncolSums(is.na(cali_ts))\ncolSums(is.na(cali_ts_fill_gaps))\n```\n:::\n\n\nForward Fill (LOCF): Uses the last known value to fill gaps. Ideal for stable or categorical data but not for volatile metrics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. APPLY LOCF TO THE CALIFORNIA DATA\n# ------------------------------------\n# We use fill() on the ZHVI_AllHomes column.\n# The default direction is \"down\", which is exactly what LOCF is.\ncali_locf <- cali_ts_fill_gaps %>%\n  fill(ZHVI_AllHomes)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cali_ts\n```\n:::\n\n\n\n#### 4.1.1 Plot the Time Series\n\nWe can make an initial plot to see that there is a trend and the data is non-stationary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncali_ts %>%\n  autoplot(ZHVI_AllHomes) +\n  labs(title = \"Zillow Home Value Index (ZHVI) for California\",\n       y = \"Home Value Index\",\n       x = \"Year\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nWe can see that filling the gaps creates some issues, this was fixed with the LOCF:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncali_ts_fill_gaps %>%\n  autoplot(ZHVI_AllHomes) +\n  labs(title = \"Zillow Home Value Index (ZHVI) for California\",\n       y = \"Home Value Index\",\n       x = \"Year\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nExploring for Seasonality which is not that evident, need further study:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# --- B. Look for Seasonality ---\n# A season plot layers the data by year, helping to spot seasonal patterns.\ncali_locf %>%\n  gg_season(ZHVI_AllHomes, labels = \"right\") +\n  labs(title = \"Seasonal Plot: ZHVI for California\",\n       y = \"Home Value Index\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nLet's plot the \"before\" and \"after\" side-by-side to see if there are any evident changes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot 1: Using the original, gappy data\np1 <- ggplot(cali_ts, aes(x = Date, y = ZHVI_AllHomes)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"Original (cali_ts)\",\n       subtitle = \"ggplot connects the dots over implicit gaps\") +\n  theme_minimal()\n\n# Plot 2: Using the data fixed with fill_gaps()\np2 <- ggplot(cali_locf, aes(x = Date, y = ZHVI_AllHomes)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"After: Forward Fill (LOCF)\",\n       subtitle = \"Gaps are filled with the last known value\") +\n  theme_minimal()\n\n# Combine them side-by-side\np1 + p2\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n\n## MISC\n\nThe naniar package is built specifically for exploring missing data. It has a miss_var_summary() function that does help visualizing missing data. Might consider implementing.\n\n```{{r}}\n# install.packages(\"naniar\")\nlibrary(naniar)\n\n# This one function does it all, already sorted!\nmiss_var_summary(all_states_data)\n\n# Example output:\n# A tibble: 271 × 3\n#   variable        n_miss  pct_miss\n#   <chr>            <int>     <dbl>\n# 1 ZRI_AllHomes_CondoCoop 149463  79.2\n# 2 ZRI_AllHomes_DuplexTriplex  142137  75.3\n# ...\n```\n\n\n### References\n\n::: {#refs}\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}